---
layout: page
title: xwMOOC 기계학습
subtitle: 소매금융 부도예측 - 독일신용 데이터
output:
  html_document: 
    keep_md: yes
  pdf_document:
    latex_engine: xelatex
mainfont: NanumGothic
---
 
> ## 학습목표 {.objectives}
>
> * 독일신용 데이터를 기준으로 통계예측모형을 개발한다.
> * 신용카드발급의 기준이 될 수 있는 컷오프를 산출한다.

``` {r, include=FALSE}
source("tools/chunk-options.R")
options(warn=-1)
```

### 1. 환경설정 및 데이터 가져오기

[R Statistical Application Development by Example](https://www.packtpub.com/big-data-and-business-intelligence/r-statistical-application-development-example-beginners-guide) 책에 부록으로 딸려있는 팩키지 "RSADBE"에 독일신용데이터가 들어 있다. 이를 바로 활용한다. 활용되는 팩키지의 각 기능은 다음과 같다.

* `pscl` &rarr; 이항회귀모형에 사용되는 $R^2$ 결정계수
* `ROCR`, `pROC` &rarr; ROC 곡선 및 AUC 면적
* `dplyr` &rarr; 데이터 작업
* `caret` &rarr; 예측모형 기본 팩키지


```{r credit-data, tidy=FALSE}
##==============================================================================
## 00. 환경설정
##==============================================================================
# R Statistical Application Development by Example
suppressMessages(library(RSADBE)) # 독일신용데이터 포함됨
suppressMessages(library(pscl)) # 이항회귀분석 R^2
suppressMessages(library(ROCR)) # 모형성능평가
suppressMessages(library(pROC))  # 모형성능평가
suppressMessages(library(caret)) # 기본예측모형
suppressMessages(library(dplyr)) # 데이터 작업

##==============================================================================
## 01. 데이터 가져오기
##==============================================================================
data(GC)
GC <- as.tbl(GC)
head(GC)
```

### 2. 데이터정제

이미 데이터가 정제되어 이항회귀모형을 적합시킬 수 있기 때문에 데이터 정제 작업은 생략하고, 바로 모형개발작업에 들어간다.

### 3. 모형개발

`createDataPartition` 함수로 훈련데이터와 검증데이터로 구분한다.

`logit.full.m` 포화모형(모든 변수가 들어간 모형)과 `logit.null.m` 상수항만 들어간 모형을 각각 이항모형에 적합시키고 나서, **BIC** 기준으로 변수를 선정하여 절약성의 원칙을 준수한 이항회귀모형을 적합시킨다.

1. *Hosmer-Lemeshow 적합성 검증(Goodness of Fit, GOF)* 검정을 통해 모형 자체 적합성을 검정한다.
1. 적합한 모형의 잔차를 분석하여 뽑아내지 못한 패턴이 있는지 점검한다.
1. 이상점, 영향점, 지렛대 관측점이 있는지를 잔차분석, 쿡거리, 지렛대점 거리계산을 통해 확인한다.

모형의 적합성은 차치하고 잔차분석을 통해 모형에 이상징후는 찾아보기 힘들다는 것을 확인할 수 있다.

```{r credit-modeling, tidy=FALSE}
##==============================================================================
## 03. 모형개발
##==============================================================================

#---------------------------------------------------------
# 3.1. 훈련데이터와 검증데이터 분리

train.id <- createDataPartition(GC$good_bad, p = 0.7)[[1]] 
gc.train.df <- GC[ train.id,] 
gc.test.df <- GC[-train.id,]

#---------------------------------------------------------
# 3.2. 모형접합 및 최적변수 선정

logit.full.m <- glm(good_bad~., data=gc.train.df, family=binomial())
logit.null.m <- glm(good_bad~1, data=gc.train.df, family=binomial())

logit.bic.m <- step(logit.null.m, scope=formula(logit.full.m), direction="both", criterion="BIC", k=log(nrow(gc.train.df)))

summary(logit.bic.m)

#---------------------------------------------------------
# 3.3. 모형 진단 및 검증

# 3.3.1. Hosmer-Lemeshow 적합성 검증(Goodness of Fit, GOF)
# Source: https://github.com/psolymos/ResourceSelection/blob/master/R/hoslem.test.R

hoslem.test <- function(x, y, g=10) {
    DNAME <- paste(deparse(substitute(x)), deparse(substitute(y)), sep=", ")
    METHOD <- "Hosmer and Lemeshow goodness of fit (GOF) test"
    yhat <- y
    y <- x
    qq <- unique(quantile(yhat, probs=seq(0, 1, 1/g)))
    cutyhat <- cut(yhat,
                   breaks = qq, include.lowest = TRUE)
    observed <- xtabs(cbind("y0"=1 - y, "y1"=y) ~ cutyhat)
    expected <- xtabs(cbind("yhat0"=1 - yhat, "yhat1"=yhat) ~ cutyhat)
    chisq <- sum((observed - expected)^2 / expected)
    PVAL = 1 - pchisq(chisq, g - 2)
    PARAMETER <- g - 2
    names(chisq) <- "X-squared"
    names(PARAMETER) <- "df"
    structure(list(statistic = chisq, parameter = PARAMETER, 
                   p.value = PVAL, method = METHOD, data.name = DNAME, observed = observed, 
                   expected = expected), class = "htest")
}
logit.bic.m.hat <- fitted(logit.bic.m)
hoslem.test(as.numeric(gc.train.df$good_bad), logit.bic.m.hat)

# 3.3.2. 잔차 분석

# 잔차 시각화
par(mfrow=c(1,3), oma=c(0,0,3,0))
plot(fitted(logit.bic.m), residuals(logit.bic.m,"response"), col="red", xlab="Fitted Values", ylab="Response Residuals")
abline(h=0)
plot(fitted(logit.bic.m), residuals(logit.bic.m,"deviance"), col="red", xlab="Fitted Values", ylab="Deviance Residuals")
abline(h=0)
plot(fitted(logit.bic.m), residuals(logit.bic.m,"pearson"), col="red", xlab="Fitted Values", ylab="Pearson Residuals")
abline(h=0)
title(main="Response, Deviance, and Pearson Residuals Comparison",outer=TRUE)

# 지렛대점 2*(p+1)/2
logit.bic.point <- hatvalues(logit.bic.m) > 2* (length(logit.bic.m$coefficients)-1)/length(logit.bic.m$y)
# 쿡 거리
logit.bic.influence.10 <- cooks.distance(logit.bic.m) >qf(0.1,length(logit.bic.m$coefficients),
                                 length(logit.bic.m$y)-length(logit.bic.m$coefficients))
logit.bic.influence.50 <- cooks.distance(logit.bic.m) >qf(0.5,length(logit.bic.m$coefficients),
                               length(logit.bic.m$y)-length(logit.bic.m$coefficients))

par(mfrow=c(1,3))
plot(dfbetas(logit.bic.m)[,1],ylab="DFBETAS - INTERCEPT")
plot(dfbetas(logit.bic.m)[,2],ylab="DFBETAS - SAT")
plot(dffits(logit.bic.m),ylab="DFFITS")
```

### 4. 모형 성능평가 및 활용

이항회귀모형을 신용평가모형으로 개발한 후, 이를 실무에 적용하기 위해서 신용카드를 발급할 것인지 거절할 것인지에 대해 컷오프를 결정해야 한다. 신용카드 발급 뿐만 아니라, 마케팅 행사에 할인쿠폰을 제시할 것인지, 신규 고객으로 유치를 적극 추진할 것인지 말 것이지 다양한 상황에 결정에 도움이 되는 것이다. 여러가지 기준이 존재하고, 다음 세가지 경우에 대해 살펴본다.

1. 정확도 기준으로 컷오프 결정
1. 민감도 + 특이성의 합이 최대가 되는 지점에서 컷오프 결정
1. 1종 오류와 2종 오류 비용이 다른 경우, 비용을 고려해서 컷오프 결정

전반적인 모형에 대한 성능에 대한 ROC 곡선 및 AUC 면적 계산등을 통해 마무리 한다.

```{r credit-performane, tidy=FALSE}
##==============================================================================
## 04. 모형성능평가
##==============================================================================
# 검증데이터 예측 시전준비

gc.logit.bic.pred <- predict(logit.bic.m, newdata=gc.test.df, type="response")
gc.logit.bic.pr <- prediction(gc.logit.bic.pred, gc.test.df$good_bad)
gc.logit.bic.prf <- performance(gc.logit.bic.pr, measure = "acc") ## 정확도 기준 최적성능 결정

#---------------------------------------------------------
# 4.1. 정확도를 극대화하는 컷오프 결정
# http://horicky.blogspot.kr/2012_06_01_archive.html
# http://stats.stackexchange.com/questions/37411/calculating-precision-and-recall-in-r

# 4.1.1. 정확도(Accuracy) 기준 컷오프 결정
bestAccInd <- which.max(gc.logit.bic.prf@"y.values"[[1]])
bestMsg <- paste("best accuracy=", gc.logit.bic.prf@"y.values"[[1]][bestAccInd], 
                 " at cutoff=", round(gc.logit.bic.prf@"x.values"[[1]][bestAccInd], 4))

plot(gc.logit.bic.prf, sub=bestMsg)


# 4.1.2. 민감도 + 특이성 최적기준 컷오프 결정
library(pROC)
rocCurve   <- roc(response = gc.test.df$good_bad,
                  predictor = gc.logit.bic.pred,
                  levels = rev(levels(gc.test.df$good_bad)), direction=">", smooth=FALSE)

plot(rocCurve, print.thres = "best", print.thres.best.method = "youden")

# 4.1.3. "최소비용" 고려한 최적 결정
gc.logit.cost.prf <- performance(gc.logit.bic.pr, "cost", cost.fp=1, cost.fn=1)

bestCostInd <- which.min(gc.logit.cost.prf@"y.values"[[1]])
costMsg <- paste("Min. Cost=", gc.logit.cost.prf@"y.values"[[1]][bestCostInd], 
                 " at cutoff=", round(gc.logit.cost.prf@"x.values"[[1]][bestCostInd], 4))

plot(gc.logit.cost.prf,sub=costMsg)


#---------------------------------------------------------
# 4.2. ROC 곡선
gc.logit.bic.prf <- performance(gc.logit.bic.pr, measure = "tpr", x.measure = "fpr") ## 정확도 기준 최적성능 결정
plot(gc.logit.bic.prf)
abline(a=0, b=1)

# ROC 면적
gc.logit.bic.auc <- performance(gc.logit.bic.pr, measure = "auc")
gc.logit.bic.auc <- gc.logit.bic.auc@y.values[[1]]
gc.logit.bic.auc
```











